{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Heat Attack Dataset\r\n",
        "This dataset was downloaded from https://www.kaggle.com/rashikrahmanpritom/heart-attack-analysis-prediction-dataset.<br>\r\n",
        "The notebook was created taking as baseline the tutorials from https://microsoftlearning.github.io/mslearn-dp100/.\r\n",
        "## Connect to a workspace"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Dataset\r\n",
        "ws = Workspace.from_config()\r\n",
        "print(ws.name, \"loaded\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "wsp-ai-915-002 loaded\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1636946795482
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check available compute resources."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Compute Resources:\")\r\n",
        "for compute_name in ws.compute_targets:\r\n",
        "    compute = ws.compute_targets[compute_name]\r\n",
        "    print(\"\\t\", compute.name, ':', compute.type)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Compute Resources:\n\t CLAI915002 : AmlCompute\n\t CI20211026 : ComputeInstance\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1636946796938
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Specify a compute cluster\r\n",
        "\r\n",
        "Uses an existing cluster, or creates a new one if there is no pre-xisting cluster."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\r\n",
        "from azureml.core.compute_target import ComputeTargetException\r\n",
        "\r\n",
        "cluster_name = \"CLAI915002\"\r\n",
        "\r\n",
        "try:\r\n",
        "    # Get existing compute target\r\n",
        "    training_cluster = ComputeTarget(workspace=ws, name=cluster_name)\r\n",
        "    print(\"Found cluster!\")\r\n",
        "except ComputeTargetException:\r\n",
        "    # Create one if it does not exist\r\n",
        "    try:\r\n",
        "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\r\n",
        "        training_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\r\n",
        "        training_cluster.wait_for_completion(show_output=True)\r\n",
        "    except Exception as ex:\r\n",
        "        print(ex)\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Found cluster!\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1636946797187
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load and register dataset\r\n",
        "**Data Description**<br>\r\n",
        "\r\n",
        "*age*: Age of the person<br>\r\n",
        "*sex*: Gender of the person<br>\r\n",
        "*cp*: chest pain type<br>\r\n",
        "*trtbps*: resting blood pressure (mm Hg)<br>\r\n",
        "*chol*: cholesterol (mg/dl)<br>\r\n",
        "*fbs*: fasting blood sugar > 120 mg/dl<br>\r\n",
        "*restecg*: resting electrocardiographic results<br>\r\n",
        "*thalachh*: maximum heart rate achieved<br>\r\n",
        "*exng*: exercise induced angina (1 = yes, 0 = no)<br>\r\n",
        "*oldpeak*: previous peak<br>\r\n",
        "*slp*: slope<br>\r\n",
        "*caa*: number of major vessels (0-3)<br>\r\n",
        "*thall*: Thal rate <br>\r\n",
        "*output*: had heart attack (target)\r\n",
        "\r\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load default datastore\r\n",
        "default_ds = ws.get_default_datastore()\r\n",
        "\r\n",
        "# Upload datasets to the datastore\r\n",
        "default_ds.upload_files(['./data/heart.csv'],\r\n",
        "                        target_path='heart-data/',\r\n",
        "                        overwrite=True,\r\n",
        "                        show_progress=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Uploading an estimated of 1 files\nUploading ./data/heart.csv\nUploaded ./data/heart.csv, 1 files out of an estimated total of 1\nUploaded 1 files\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "$AZUREML_DATAREFERENCE_95b4490356e241279422f512e20d581c"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1636946798625
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create tabular dataset with heart data\r\n",
        "heart_tab = Dataset.Tabular.from_delimited_files(path=(default_ds, 'heart-data/heart.csv'))\r\n",
        "heart_tab.to_pandas_dataframe()\r\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "     age  sex  cp  trtbps  chol  fbs  restecg  thalachh  exng  oldpeak  slp  \\\n0     63    1   3     145   233    1        0       150     0      2.3    0   \n1     37    1   2     130   250    0        1       187     0      3.5    0   \n2     41    0   1     130   204    0        0       172     0      1.4    2   \n3     56    1   1     120   236    0        1       178     0      0.8    2   \n4     57    0   0     120   354    0        1       163     1      0.6    2   \n..   ...  ...  ..     ...   ...  ...      ...       ...   ...      ...  ...   \n298   57    0   0     140   241    0        1       123     1      0.2    1   \n299   45    1   3     110   264    0        1       132     0      1.2    1   \n300   68    1   0     144   193    1        1       141     0      3.4    1   \n301   57    1   0     130   131    0        1       115     1      1.2    1   \n302   57    0   1     130   236    0        0       174     0      0.0    1   \n\n     caa  thall  output  \n0      0      1       1  \n1      0      2       1  \n2      0      2       1  \n3      0      2       1  \n4      0      2       1  \n..   ...    ...     ...  \n298    0      3       0  \n299    0      3       0  \n300    2      3       0  \n301    1      3       0  \n302    1      2       0  \n\n[303 rows x 14 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>cp</th>\n      <th>trtbps</th>\n      <th>chol</th>\n      <th>fbs</th>\n      <th>restecg</th>\n      <th>thalachh</th>\n      <th>exng</th>\n      <th>oldpeak</th>\n      <th>slp</th>\n      <th>caa</th>\n      <th>thall</th>\n      <th>output</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>63</td>\n      <td>1</td>\n      <td>3</td>\n      <td>145</td>\n      <td>233</td>\n      <td>1</td>\n      <td>0</td>\n      <td>150</td>\n      <td>0</td>\n      <td>2.3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>37</td>\n      <td>1</td>\n      <td>2</td>\n      <td>130</td>\n      <td>250</td>\n      <td>0</td>\n      <td>1</td>\n      <td>187</td>\n      <td>0</td>\n      <td>3.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>41</td>\n      <td>0</td>\n      <td>1</td>\n      <td>130</td>\n      <td>204</td>\n      <td>0</td>\n      <td>0</td>\n      <td>172</td>\n      <td>0</td>\n      <td>1.4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>56</td>\n      <td>1</td>\n      <td>1</td>\n      <td>120</td>\n      <td>236</td>\n      <td>0</td>\n      <td>1</td>\n      <td>178</td>\n      <td>0</td>\n      <td>0.8</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>57</td>\n      <td>0</td>\n      <td>0</td>\n      <td>120</td>\n      <td>354</td>\n      <td>0</td>\n      <td>1</td>\n      <td>163</td>\n      <td>1</td>\n      <td>0.6</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>298</th>\n      <td>57</td>\n      <td>0</td>\n      <td>0</td>\n      <td>140</td>\n      <td>241</td>\n      <td>0</td>\n      <td>1</td>\n      <td>123</td>\n      <td>1</td>\n      <td>0.2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>299</th>\n      <td>45</td>\n      <td>1</td>\n      <td>3</td>\n      <td>110</td>\n      <td>264</td>\n      <td>0</td>\n      <td>1</td>\n      <td>132</td>\n      <td>0</td>\n      <td>1.2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>300</th>\n      <td>68</td>\n      <td>1</td>\n      <td>0</td>\n      <td>144</td>\n      <td>193</td>\n      <td>1</td>\n      <td>1</td>\n      <td>141</td>\n      <td>0</td>\n      <td>3.4</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>301</th>\n      <td>57</td>\n      <td>1</td>\n      <td>0</td>\n      <td>130</td>\n      <td>131</td>\n      <td>0</td>\n      <td>1</td>\n      <td>115</td>\n      <td>1</td>\n      <td>1.2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>302</th>\n      <td>57</td>\n      <td>0</td>\n      <td>1</td>\n      <td>130</td>\n      <td>236</td>\n      <td>0</td>\n      <td>0</td>\n      <td>174</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>303 rows × 14 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1636946808719
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Register heart dataset\r\n",
        "heart_tab = heart_tab.register(workspace=ws,\r\n",
        "                            name='heart',\r\n",
        "                            description='heart attack data',\r\n",
        "                            tags={'format':'CSV'},\r\n",
        "                            create_new_version=True)\r\n"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1636946809062
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check existing datasets and versions."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Datasets:\")\r\n",
        "for dataset_name in list(ws.datasets.keys()):\r\n",
        "    dataset = Dataset.get_by_name(ws, dataset_name)\r\n",
        "    print(\"\\t\", dataset.name, 'version', dataset.version)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Datasets:\n\t o2 version 1\n\t heart version 2\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1636946809347
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check data\r\n",
        "\r\n",
        "Making sure there are no missinng values, and taking a look at the descriptive statictics for the dataset."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for Null values\r\n",
        "heart_tab.to_pandas_dataframe().isnull().sum()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "age         0\nsex         0\ncp          0\ntrtbps      0\nchol        0\nfbs         0\nrestecg     0\nthalachh    0\nexng        0\noldpeak     0\nslp         0\ncaa         0\nthall       0\noutput      0\ndtype: int64"
          },
          "metadata": {}
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1636946809688
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Look inside\r\n",
        "heart_tab.to_pandas_dataframe().describe()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": "              age         sex          cp      trtbps        chol         fbs  \\\ncount  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \nmean    54.366337    0.683168    0.966997  131.623762  246.264026    0.148515   \nstd      9.082101    0.466011    1.032052   17.538143   51.830751    0.356198   \nmin     29.000000    0.000000    0.000000   94.000000  126.000000    0.000000   \n25%     47.500000    0.000000    0.000000  120.000000  211.000000    0.000000   \n50%     55.000000    1.000000    1.000000  130.000000  240.000000    0.000000   \n75%     61.000000    1.000000    2.000000  140.000000  274.500000    0.000000   \nmax     77.000000    1.000000    3.000000  200.000000  564.000000    1.000000   \n\n          restecg    thalachh        exng     oldpeak         slp         caa  \\\ncount  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \nmean     0.528053  149.646865    0.326733    1.039604    1.399340    0.729373   \nstd      0.525860   22.905161    0.469794    1.161075    0.616226    1.022606   \nmin      0.000000   71.000000    0.000000    0.000000    0.000000    0.000000   \n25%      0.000000  133.500000    0.000000    0.000000    1.000000    0.000000   \n50%      1.000000  153.000000    0.000000    0.800000    1.000000    0.000000   \n75%      1.000000  166.000000    1.000000    1.600000    2.000000    1.000000   \nmax      2.000000  202.000000    1.000000    6.200000    2.000000    4.000000   \n\n            thall      output  \ncount  303.000000  303.000000  \nmean     2.313531    0.544554  \nstd      0.612277    0.498835  \nmin      0.000000    0.000000  \n25%      2.000000    0.000000  \n50%      2.000000    1.000000  \n75%      3.000000    1.000000  \nmax      3.000000    1.000000  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>cp</th>\n      <th>trtbps</th>\n      <th>chol</th>\n      <th>fbs</th>\n      <th>restecg</th>\n      <th>thalachh</th>\n      <th>exng</th>\n      <th>oldpeak</th>\n      <th>slp</th>\n      <th>caa</th>\n      <th>thall</th>\n      <th>output</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>303.000000</td>\n      <td>303.000000</td>\n      <td>303.000000</td>\n      <td>303.000000</td>\n      <td>303.000000</td>\n      <td>303.000000</td>\n      <td>303.000000</td>\n      <td>303.000000</td>\n      <td>303.000000</td>\n      <td>303.000000</td>\n      <td>303.000000</td>\n      <td>303.000000</td>\n      <td>303.000000</td>\n      <td>303.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>54.366337</td>\n      <td>0.683168</td>\n      <td>0.966997</td>\n      <td>131.623762</td>\n      <td>246.264026</td>\n      <td>0.148515</td>\n      <td>0.528053</td>\n      <td>149.646865</td>\n      <td>0.326733</td>\n      <td>1.039604</td>\n      <td>1.399340</td>\n      <td>0.729373</td>\n      <td>2.313531</td>\n      <td>0.544554</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>9.082101</td>\n      <td>0.466011</td>\n      <td>1.032052</td>\n      <td>17.538143</td>\n      <td>51.830751</td>\n      <td>0.356198</td>\n      <td>0.525860</td>\n      <td>22.905161</td>\n      <td>0.469794</td>\n      <td>1.161075</td>\n      <td>0.616226</td>\n      <td>1.022606</td>\n      <td>0.612277</td>\n      <td>0.498835</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>29.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>94.000000</td>\n      <td>126.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>71.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>47.500000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>120.000000</td>\n      <td>211.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>133.500000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>55.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>130.000000</td>\n      <td>240.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>153.000000</td>\n      <td>0.000000</td>\n      <td>0.800000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>61.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>140.000000</td>\n      <td>274.500000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>166.000000</td>\n      <td>1.000000</td>\n      <td>1.600000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>77.000000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>200.000000</td>\n      <td>564.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>202.000000</td>\n      <td>1.000000</td>\n      <td>6.200000</td>\n      <td>2.000000</td>\n      <td>4.000000</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1636946809967
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train a model from script\r\n",
        "\r\n",
        "Create an experiment folder."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\r\n",
        "\r\n",
        "# Create a folder for the experiment files\r\n",
        "experiment_folder = 'heart_training_hyperdrive'\r\n",
        "os.makedirs(experiment_folder, exist_ok=True)"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1636946810213
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create an environment file."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $experiment_folder/hyperdrive_env.yml\r\n",
        "name: hyperdrive_env\r\n",
        "dependencies:\r\n",
        "- python=3.6.2\r\n",
        "- scikit-learn\r\n",
        "- ipykernel\r\n",
        "- matplotlib\r\n",
        "- pandas\r\n",
        "- numpy\r\n",
        "- pip\r\n",
        "- pip:\r\n",
        "  - azureml-defaults"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting heart_training_hyperdrive/hyperdrive_env.yml\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating experiment script, using a gradient boosting classifier. Observe the hyperparameters to be tunned are learning rate and number of estimators."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $experiment_folder/heart_training.py\r\n",
        "# Import libraries\r\n",
        "import os\r\n",
        "import argparse\r\n",
        "from azureml.core import Run, Dataset\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import joblib\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.ensemble import GradientBoostingClassifier\r\n",
        "\r\n",
        "# Get script argument input dataset and hyperparameters\r\n",
        "parser = argparse.ArgumentParser()\r\n",
        "parser.add_argument(\"--ds\", type=str, dest='ds_id')\r\n",
        "parser.add_argument(\"--learning_rate\", type=float, dest='learning_rate', default=0.1)\r\n",
        "parser.add_argument(\"--n_estimators\", type=int, dest='n_estimators', default=100)\r\n",
        "args = parser.parse_args()\r\n",
        "\r\n",
        "# Get experiment run context\r\n",
        "run = Run.get_context()\r\n",
        "\r\n",
        "# Log hyperparameter values\r\n",
        "run.log('learning_rate', np.float(args.learning_rate))\r\n",
        "run.log('n_estimators', np.float(args.n_estimators))\r\n",
        "\r\n",
        "# Get training dataset\r\n",
        "print(\"Loading Data...\")\r\n",
        "ws = run.experiment.workspace\r\n",
        "heart = run.input_datasets['heart_dataset'].to_pandas_dataframe()\r\n",
        "\r\n",
        "# Separate features and labels\r\n",
        "y = heart['output'].values\r\n",
        "X = heart.drop(['output'], axis=1).values\r\n",
        "\r\n",
        "# Split data into train and test sets\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\r\n",
        "\r\n",
        "# Train a random forest model\r\n",
        "print('Training a Gradient Boosting Classifier model with default hyperparameters.')\r\n",
        "model = GradientBoostingClassifier(learning_rate=args.learning_rate,\r\n",
        "                                    n_estimators=args.n_estimators).fit(X_train, y_train)\r\n",
        "\r\n",
        "# Calculate accuracy\r\n",
        "y_hat = model.predict(X_test)\r\n",
        "model_accuracy = np.average(y_hat == y_test)\r\n",
        "print('Accuracy: ', model_accuracy)\r\n",
        "run.log('Accuracy', np.float(model_accuracy))\r\n",
        "\r\n",
        "os.makedirs('outputs', exist_ok=True)\r\n",
        "joblib.dump(value=model, filename='outputs/heart_model_hyperdrive.pkl')\r\n",
        "\r\n",
        "run.complete()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting heart_training_hyperdrive/heart_training.py\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running the experiment script. The hyperparameter tuning configuration includes the following:\r\n",
        "- Two hyperparameters to be tunned: learning rate and number of estimators;\r\n",
        "- Random samplig is used to select hyperparameter values;\r\n",
        "- An early termination policy based on running averages of the primary metric;\r\n",
        "- The goal is to maximize accuracy."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Experiment, ScriptRunConfig, Environment\r\n",
        "from azureml.widgets import RunDetails\r\n",
        "from azureml.train.hyperdrive import RandomParameterSampling, HyperDriveConfig, PrimaryMetricGoal, uniform, choice, MedianStoppingPolicy\r\n",
        "\r\n",
        "# Create python environment for the experiment (from a .yml file)\r\n",
        "env = Environment.from_conda_specification(\"hyperdrive_env\", experiment_folder + \"/hyperdrive_env.yml\")\r\n",
        "\r\n",
        "# Get training dataset\r\n",
        "heart_ds = ws.datasets.get(\"heart\")\r\n",
        "\r\n",
        "# Get a script config\r\n",
        "script_config = ScriptRunConfig(source_directory=experiment_folder,\r\n",
        "                                script='heart_training.py',\r\n",
        "                                arguments=['--ds', heart_ds.as_named_input('heart_dataset')],\r\n",
        "                                environment=env,\r\n",
        "                                compute_target=cluster_name)\r\n",
        "\r\n",
        "params = RandomParameterSampling({\r\n",
        "                                    \"learning_rate\": uniform(0.10, 0.15),\r\n",
        "                                    \"n_estimators\": choice(60, 70, 80)\r\n",
        "                                   })\r\n",
        "\r\n",
        "early_termination_policy = MedianStoppingPolicy(evaluation_interval=1, delay_evaluation=5)\r\n",
        "\r\n",
        "# Configure hyperdrive settings\r\n",
        "hyperdrive = HyperDriveConfig(run_config=script_config,\r\n",
        "                            hyperparameter_sampling=params,\r\n",
        "                            policy=early_termination_policy,\r\n",
        "                            primary_metric_name='Accuracy',\r\n",
        "                            primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\r\n",
        "                            max_total_runs=20,\r\n",
        "                            max_concurrent_runs=2\r\n",
        "                            )\r\n",
        "\r\n",
        "# Submit the experiment\r\n",
        "experiment_name = 'train-heart-hyperdrive'\r\n",
        "experiment = Experiment(workspace=ws, name=experiment_name)\r\n",
        "run = experiment.submit(config=hyperdrive)\r\n",
        "RunDetails(run).show()\r\n",
        "run.wait_for_completion()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1636949929866
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the best performing run."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for child in run.get_children():\r\n",
        "    print(child.get_metrics())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{'learning_rate': 0.14647713520351516, 'n_estimators': 60.0, 'Accuracy': 0.8157894736842105}\n{'learning_rate': 0.11618236886733278, 'n_estimators': 60.0, 'Accuracy': 0.8289473684210527}\n{'learning_rate': 0.10759394589582, 'n_estimators': 70.0, 'Accuracy': 0.8026315789473685}\n{'learning_rate': 0.12361103871615381, 'n_estimators': 60.0, 'Accuracy': 0.8026315789473685}\n{'learning_rate': 0.12055256990308783, 'n_estimators': 70.0, 'Accuracy': 0.8157894736842105}\n{'learning_rate': 0.12445324622760633, 'n_estimators': 80.0, 'Accuracy': 0.8157894736842105}\n{'learning_rate': 0.14707108694134272, 'n_estimators': 60.0, 'Accuracy': 0.8157894736842105}\n{'learning_rate': 0.13072844007802958, 'n_estimators': 80.0, 'Accuracy': 0.8157894736842105}\n{'learning_rate': 0.14245353096359964, 'n_estimators': 70.0, 'Accuracy': 0.7894736842105263}\n{'learning_rate': 0.12785117783486208, 'n_estimators': 80.0, 'Accuracy': 0.8026315789473685}\n{'learning_rate': 0.1450678457816757, 'n_estimators': 60.0, 'Accuracy': 0.8421052631578947}\n{'learning_rate': 0.13362784972236388, 'n_estimators': 70.0, 'Accuracy': 0.7894736842105263}\n{'learning_rate': 0.11186783227217904, 'n_estimators': 70.0, 'Accuracy': 0.8157894736842105}\n{'learning_rate': 0.13510129995347983, 'n_estimators': 60.0, 'Accuracy': 0.7894736842105263}\n{'learning_rate': 0.13250080771084094, 'n_estimators': 80.0, 'Accuracy': 0.8157894736842105}\n{'learning_rate': 0.13826702453320627, 'n_estimators': 70.0, 'Accuracy': 0.8157894736842105}\n{'learning_rate': 0.13839258538321714, 'n_estimators': 60.0, 'Accuracy': 0.8026315789473685}\n{'learning_rate': 0.10610324368350516, 'n_estimators': 60.0, 'Accuracy': 0.7763157894736842}\n{'learning_rate': 0.13501607355772438, 'n_estimators': 70.0, 'Accuracy': 0.8026315789473685}\n{'learning_rate': 0.1351715719210146, 'n_estimators': 80.0, 'Accuracy': 0.8157894736842105}\n"
        }
      ],
      "execution_count": 27,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1636950032592
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best run\r\n",
        "best_run = run.get_best_run_by_primary_metric()\r\n",
        "best_run_metrics = best_run.get_metrics()\r\n",
        "script_arguments = best_run.get_details()['runDefinition']['arguments']\r\n",
        "\r\n",
        "print('  -Accuracy:', best_run_metrics['Accuracy'])\r\n",
        "print('  -Arguments:', script_arguments)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "  -Accuracy: 0.8421052631578947\n  -Arguments: ['--ds', 'DatasetConsumptionConfig:heart_dataset', '--learning_rate', '0.1450678457816757', '--n_estimators', '60']\n"
        }
      ],
      "execution_count": 29,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1636950068150
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}